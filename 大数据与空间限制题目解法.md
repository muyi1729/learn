# 解题技巧

- 哈希函数可以把数据按照种类均匀分流
- 布隆过滤器用于集合的建立与查询，并可以节省大量空间
- 一致性哈希解决数据服务器的负载管理问题
- 利用并查集结构做岛问题的并行计算
- 位图解决某一范围上数字的出现情况，并可以节省大量空间
- 利用分段统计思想、并进一步节省大量空间
- 利用堆、外排序来做多个处理单元的结果合并

# 认识布隆过滤器（黑名单系统）

## 题目

不安全网页的黑名单包含 100 亿个黑名单网页，每个网页的 URL 最多占用64B。现在想要实现一种网页过滤系统，可以根据网页的 URL 判断该网页是否在黑名单上，请设计该系统。

## 要求

1. 该系统允许有万分之一以下的判断失误率。
2. 使用的额外空间不要超过 30GB。

## 解答

如果将这 100 亿个 URL 通过数据库或哈希表保存起来，就可以对每条 URL 进行查询，但是每个 URL 有 64B，数量是 100 亿个，所以至少需要 640GB 的空间，不满足要求 2。

> 如果面试者遇到网页黑名单系统、垃圾邮件过滤系统，爬虫的网页判重系统等题目，又看到系统容忍一定程度的失误率，但是对空间要求比较严格，那么很可能是面试官希望面试者具备布隆过滤器的知识。一个布隆过滤器精确地代表一个集合，并可以精确判断一个元素是否在集合中。注意，只是精确代表和精确判断，到底有多精确呢？则完全在于你具体的设计，但想做到完全正确是不可能的。布隆过滤器的优势就在于使用很少的空间就可以将准确率做到很高的程度。该结构由Burton Howard Bloom于1970年提出。

那么什么是布隆过滤器呢？

假设有一个长度为 m 的 bit 类型的数组，即数组的每个位置只占一个 bit，如果我们所知，每一个 bit 只有 0 和 1 两种状态，如图所示：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322094445.jpeg)

再假设一共有 k 个哈希函数，这些函数的输出域 S 都大于或等于 m，并且这些哈希函数都足够优秀且彼此之间相互独立（将一个哈希函数的计算结果乘以 6 除以 7 得出的新哈希函数和原函数就是相互独立的）。那么对同一个输入对象（假设是一个字符串，记为 URL），经过 k 个哈希函数算出来的结果也是独立的。可能相同，也可能不同，但彼此独立。对算出来的每一个结果都对 m 取余（%m），然后在 bit array 上把相应位置设置为 1（我们形象的称为涂黑）。如图所示：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322094517.jpeg)

我们把 bit 类型的数组记为 bitMap。至此，一个输入对象对 bitMap 的影响过程就结束了，也就是 bitMap 的一些位置会被涂黑。接下来按照该方法，处理所有的输入对象（黑名单中的 100 亿个URL）。每个对象都可能把 bitMap 中的一些白位置涂黑，也可能遇到已经涂黑的位置，遇到已经涂黑的位置让其继续为黑即可。处理完所有的输入对象后，可能 bitMap 中已经有相当多的位置被涂黑。至此，一个布隆过滤器生成完毕，这个布隆过滤器代表之前所有输入对象组成的集合。 

那么在检查阶段时，如何检查一个对象是否是之前的某一个输入对象呢（判断一个 URL 是否是黑名单中的 URL）？假设一个对象为 a，想检查它是否是之前的输入对象，就把 a 通过 k 个哈希函数算出 k 个值，然后把 k 个值都取余（%m），就得到在 [0,m-1] 范围上的 k 个值。接下来在 bitMap 上看这些位置是不是都为黑。如果有一个不为黑，说明 a 一定不再这个集合里。如果都为黑，说明 a 在这个集合里，但可能误判。 

再解释具体一点，如果 a 的确是输入对象 ，那么在生成布隆过滤器时，bitMap中相应的 k 个位置一定已经涂黑了，所以在检查阶段，a 一定不会被漏过，这个不会产生误判。会产生误判的是，a 明明不是输入对象，但如果在生成布隆过滤器的阶段因为输入对象过多，而 bitMap 过小，则会导致 bitMap 绝大多数的位置都已经变黑。那么在检查 a 时，可能 a 对应的 k 个位置都是黑的，从而错误地认为 a 是输入对象（即是黑名单中的 URL）。通俗地说，布隆过滤器的失误类型是“宁可错杀三千，绝不放过一个”。 

 布隆过滤器到底该怎么生成呢？只需记住下列三个公式即可： 

- 对于输入的数据量 n（这里是 100 亿）和失误率 p（这里是万分之一），布隆过滤器的大小 m：m = - (n* lnp)/(ln2*ln2)，计算结果向上取整（这道题 m=19.19n，向上取整为 20n，即需要 2000 亿个bit，也就是 25GB） 
- 需要的哈希函数的个数 k：k = ln2 * m/n = 0.7 * m/n（这道题 k = 0.7 * 20n/n = 14） 
- 由于前两步都进行了向上取整，那么由前两步确定的布隆过滤器的真正失误率 p：p = (1 - e^(-nk/m) )^k

> 布隆过滤器 (Bloom Filter) 详解：https://www.cnblogs.com/allensun/archive/2011/02/16/1956532.html

# 只用2GB内存在20亿个整数中找到出现次数最多的数

## 题目

有一个包含20亿个全是32位整数的大文件，在其中找到出现次数最多的数。

## 要求

内存限制位2GB。

## 解答

想要在很多整数中找到出现次数最多的数，通常的做法是 **使用哈希表对出现的每一个数做词频统计**，哈希表的key是某一个整数，value是这个数出现的次数。本题共有20亿个数，哪怕只是一个数出现了20亿次，用32位的整数也可以表示其出现的次数而不会产生溢出，所以哈希表的key需要占用4字节，value也是4字节。那么哈希表的一条记录（key,value）需要占用8字节，当哈希表记录数为2亿个时，需要至少1.6GB的内存。

但如果20亿个数中不同的数超过2亿种，最极端的情况是20亿个数都不同，那么在哈希表中需要产生20亿条记录，这样内存会不够用，所以不能一次性用哈希表统计20亿个数。

解决办法是 **把包含20亿个数的大文件用哈希函数分成16个小文件**（根据内存限制2GB的条件确定），根据 **哈希函数的性质**，同一种数不可能被哈希到不同的小文件上，同时每个小文件中不同的数一定不会大于2亿种，假设哈希函数足够好。然后 **对每一个小文件用哈希表来统计其中每种数出现的次数**，这样就得到了16个小文件中各自出现次数最多的数，还有各自的次数统计。接下来只要选出这16个小文件各自的第一名中谁出现的次数最多即可。

> 把一个大的集合通过哈希函数分配到多台机器中，或者分配到多个文件里，这种技巧是处理大数据面试题最常用的技巧之一。但是到底分配到多少台机器、分配到多少文件，在解题时一定要确定下来。可能是在与面试官沟通的过程中由面试官指定，也可能根据具体的限制来确定。

# 40亿个非负整数中找到没出现的数

## 题目

32 位无符号整数的范围是 0~4,294,967,295，现在有一个正好包含 40 亿个无符号整数的文件，所以在整个范围中必然存在没出现过的数。可以使用最多 1GB 的内存，怎么找到所有未出现过的数？

**进阶**：内存限制为 10MB，但是只用找到一个没出现过的数即可。

## 解答

### 原问题

如果用哈希表 HashSet 来保存出现过的数，那么如果 40 亿个数都不同，则哈希表的记录数为 40 亿条，存一个 32 位整数需要 4 字节，所以最差情况下需要 40亿×4B=160 亿字节，大约需要 16 GB的空间，不符合要求。

哈希表需要占用很多空间，可以 **使用 bitmap 的方式来表示数出现的情况**。具体地说，是申请一个长度为 4,294,967,295 的 bit 类型的数组 bitArr，bitArr 上的每个位置只可以表示 0 或者 1 状态。8 个 bit 为 1 B，所以长度为 4,294,967,295 的 bit 类型的数组占用 500MB 空间。

则么使用这个 bitArr 数组呢？就是遍历这 40 亿个无符号数，如果出现了，就将数组相应位置的值设置为 1。例如，遇到 7000，就把 bitArr[7000] 设置为1。

遍历完成后，再依次遍历 bitArr，哪个位置上的值没被设置为1 ，哪个数就不在 40 亿个数中。遍历完 bitArr 后，所有没出现过的数就都找出来了。

### 进阶问题

现在只有 10MB 的内存，但也只要求找到其中一个没出现过的数即可。首先，0~4,294,967,295 这个范围是可以平均分成 64（根据下述第二次遍历时的 bitArr 大小确定）个区间的，每个区间是 67108864 个数，例如：第 0 区间（0 ~ 67108863）、第 1 区间（67108864 ~ 134217728）、第 i 区间（67108864×i ~ 67108864×(i+1)-1），......因为一共只有 40 亿个数，所以，如果统计落在每一个区间上的数有多少，肯定有至少一个区间上的计数少于 67108864。利用这一点可以找出其中一个没出现过的数。具体过程为：

第一次遍历时，先申请长度为 64 的整型数组 countArr[0..63]，countArr[i] 用来统计区间 i 上的数有多少。遍历 40 亿个数，根据当前数是多少来决定哪一个区间上的计数增加。例如，如果当前数是 3422552090，3422552090/67108864=51，所以第 51 区间上的计数增加 countArr[51]++。遍历完 40 亿个数之后，遍历 countArr，必然会有某一个位置上的值（countArr[i]）小于 67108864，表示第 i 区间上至少有一个数没出现过。肯定会找到一个这样的区间。此时使用的内存就是 countArr 的大小（64×4B），是非常小的。

假设找到第 37 区间上的计数小于 67108864，以下为第二次遍历的过程：

1. 申请长度为 67108864 的 bitmap，这占用大约 8 MB的空间，记为 bitArr[0..67108863]；
2. 再遍历一次 40 亿个数，此时的遍历只关注落在第 37 区间上的数，记为 num(num/67108864==37)，其它区间的数全部忽略。
3. 如果步骤 2 的 num 在第 37 区间上，将 bitArr[num-67108864*37] 的值设置为 1，也就是只做第 37 区间上的数的 bitArr 映射。
4. 遍历完 40 亿个数之后，在 bitArr 上必然存在没被设置成 1 的位置，假设第 i 个位置上的值没设置成 1，那么 67108864×37+i 这个数就是一个没出现过的数。

总结一下进阶的解法：

1. 根据 10MB 的内存限制，确定统计区间的大小，就是第二次遍历时的 bitArr 大小。
2. 利用区间计数的方式，找到那个计数不足的区间，这个区间上肯定有没出现的数。
3. 对这个区间上的数做 bitmap 映射，再遍历 bitmap，找到一个没出现的数即可。

# 40亿个非负整数中找到出现两次的数

## 题目

32 位无符号整数的范围是 0~4294967295，现在有 40 亿个无符号整数，可以使用最多 1GB 的内存，找出所有出现了两次的数。

## 解答

可以用 **bitmap** 的方式来表示数出现的情况。具体的说，申请一个长度为 4294967295×2 的 bit 类型的数组 bitArr，**用 2 个位置表示一个数出现的词频**，1B 占用 8 个 bit，所以长度为 4294967295×2 的 bit 类型的数组占用 1GB 空间。则么使用这个 bitArr 呢？遍历这 40 亿个无符号数，如果初次遇到num，就把 bit[num* 2+1] 和 bitArr[num* 2] 设置为 01，如果第二次遇到num，就把 bit[num* 2+1] 和 bitArr[num* 2] 设置为 10，如果第三次遇到num，就把 bit[num* 2+1] 和 bitArr[num* 2] 设置为 11。以后再遇到 num，发现此时 bit[num* 2+1] 和 bitArr[num* 2] 已经被设置为 11，就不再做任何设置。遍历完成后，再依次遍历 bitArr，如果发现 bit[i* 2+1] 和 bitArr[i* 2] 设置为 10，那么 i 就是出现了两次的数。

# 40亿个非负整数中找到所有数的中位数

## 题目

可以使用最多 10MB 的内存，怎么找到这 40 亿个整数的中位数？

## 解答

**用分区间的方式处理**，长度为 2MB 的无符号整型数组占用的空间为 8MB，所以将区间的数量定为 4294967295/2M，向上取整为 2148 个区间。第 0 区间为 0~2M-1，第 1 区间为 2M~4M-1，第 i 区间为 2M×i~2M×(i+1)-1......

申请一个长度为 2148 的无符号整型数组 arr[0..2147]，arr[i] 表示第 i 区间由多少个数。arr 必然小于 10MB。然后遍历 40 亿个数，如果遍历到当前数为 num，先看 num 落在哪个区间上（num/2M），然后将对应的进行 arr[num/2M]++ 操作。这样遍历下来，就得到了每一个区间的数的出现状况，**通过累加每个区间的出现次数，就可以找到 40 亿个数的中位数（也是第 20 亿个数）到底落在哪个区间上**。比如，0~K-1 区间上数的个数为 19.998 亿，但是发现当加上第 K 个区间上数的个数之后就超过了 20 亿，那么可以知道第 20 亿个数是第 K 区间上的数，并且可以知道第 20 亿个数是第 K 区间上的第 0.002 亿个数。

接下来申请一个长度为 2MB 的无符号整型数组 countArr[0..2M-1]，占用空间 8MB。然后再遍历 40 亿个数，此时只关心处在第 K 区间的数，记为 numi，其他的数省略，然后将 countArr[numi-K*2M]++，也就是只对第 K 区间的数做频率统计。这次遍历完 40 亿个数之后，就得到了第 K 区间的词频统计结果 countArr，最后只在第 K 区间上找到第 0.002 亿个数即可。

# 找到100亿个URL中重复的URL

## 题目

有一个包含 100 亿个 URL 的大文件，假设每个 URL 占用 64B，请找出其中所有重复的 URL。

## 解答

使用解决大数据问题的常规方法：把大文件通过哈希函数分配到机器，或者通过哈希函数把大文件拆成小文件。一直进行这种划分，直到划分的结果满足资源限制的要求。首先，要向面试官询问资源上的限制有哪些，包括内存、计算时间等要求。在明确了限制要求之后，可以将每条 URL 通过哈希函数分配到若干机器或者拆分成若干小文件，这里的“若干”由具体的资源限制来计算出精确的数量。

例如，将 100 亿字节的大文件通过哈希函数分配到 100 台机器上，然后每一台机器分别统计分给自己的 URL 是否有重复的URL，同时哈希函数的性质决定了同一条 URL 不可能分给不同的机器；或者在单机上将大文件通过哈希函数拆成 1000 个小文件，对每一个小文件再利用哈希表遍历，找出重复的 URL；或者在分给机器或拆完文件之后，进行排序，排序过后再看是否有重复的 URL 出现。总之，牢记一点，很多大数据问题都离不开分流，要么是哈希函数把大文件的内容分配给不同的机器，要么是哈希函数把大文件拆成小文件，然后处理每一个小数量的集合。

# 搜索词汇的top K问题

## 题目

某搜索公司一天的用户搜索词汇是海量的(百亿数据量)，请设计一种求出每天热门 top 100 词汇的可行办法。

## 解答

最开始还是用**哈希分流**的思路来处理，把包含百亿数据量的词汇文件分流到不同的机器上，具体多少台机器由面试官规定或者更多的限制来决定。对每一台机器来说，如果分到的数据量依然很大，比如，内存不够或其他问题，可以**再用哈希函数把每台机器的分流文件拆成更小的文件处理**。处理每一个小文件的时候，哈希表统计每种词及其词频，哈希表记录建立完成后，再遍历哈希表，遍历哈希表的过程中使用大小为 100 的**大根堆**来选出每一个小文件的 top 100（整体未排序的 top 100）。然后把各个小文件的 top 100 **进行外排序或者继续利用大根堆**，就可以选出每台机器上的 top 100。不同机器之间的 top 100 再进行外排序或者继续利用大根堆，最终求出整个百亿数据量中的 top 100。

对于 top K 的问题，除哈希函数分流和用哈希表做词频统计之外，还经常用堆结构和外排序的手段进行处理。

# 一致性哈希算法的基本原理

## 题目

工程师常使用服务器集群来设计和实现数据缓存，以下是常见的策略： 

1. 无论是添加、查询还是删除数据，都先将数据的 id 通过哈希函数换成一个哈希值，记为 key 。
2. 如果目前机器有 N 台，则计算 key%N 的值，这个值就是该数据所属的机器编号，无论是添加、删除还是查询操作，都只在这台机器上进行。 

 请分析这种缓存策略可能带来的问题，并提出改进的方案。

## 解答

题目中描述的缓存策略的潜在问题是，如果增加或删除机器时（N变化）代价会很高，所有的数据都不得不根据 id 重新计算一遍哈希值，并将哈希值对新的机器数进行取模操作。然后进行大规模的数据迁移。 

为了解决这些问题，下面介绍一下一致性哈希算法，这是一种很好的数据缓存设计方案。我们假设数据的 id 通过哈希函数转换成的哈希值范围是 2^32 ，也就是 0~(2^32)-1 的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形，那么一个数据 id 在计算出哈希值之后认为对应到环中的一个位置上，如图所示：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322095521.jpeg)

接下来想象有三台机器也处在这样一个环中，这三台机器在环中的位置根据机器id（主机名或者主机 IP，是主机唯一的就行）计算出的哈希值对 2^32 取模对应到环上。那么一条数据如何确定归属哪台机器呢？我们可以在该数据对应环上的位置顺时针寻找离该位置最近的机器，将数据归属于该机器上：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322095543.jpeg)

这样的话，如果删除 machine2 节点，则只需将 machine2 上的数据迁移到 machine3 上即可，而不必大动干戈迁移所有数据。当添加节点的时候，也只需将新增节点到逆时针方向新增节点前一个节点这之间的数据迁移给新增节点即可。 

 但这时还是存在如下两个问题： 

- 机器较少时，通过机器 id 哈希将机器对应到环上之后，几个机器可能没有均分环

  ![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322095611.jpeg)

  那么这样会导致负载不均。

- 增加机器时，可能会打破现有的平衡：

  ![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322095635.jpeg)

为了解决这种数据倾斜问题，一致性哈希算法引入了**虚拟节点机制**，即对每一台机器通过不同的哈希函数计算出多个哈希值，对多个位置都放置一个服务节点，称为虚拟节点。具体做法：比如对于 machine1 的 IP192.168.25.132（或机器名），计算出 192.168.25.132-1、192.168.25.132-2、192.168.25.132-3、192.168.25.132-4 的哈希值，然后对应到环上，其他的机器也是如此，这样的话节点数就变多了，根据哈希函数的性质，平衡性自然会变好：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210322095655.jpeg)

此时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，比如上图的查找表。当某一条数据计算出归属于 m1-2 时再根据查找表的跳转，数据将最终归属于实际的 m1 节点。 

>  基于一致性哈希的原理有很多种具体的实现，包括 Chord 算法、KAD 算法等，有兴趣的话可以进一步学习。

# 相关题目

40亿个无符号整数，给一个数判断是否存在，要求内存1g。假如这40个数字需要作为黑名单，不经过磁盘IO，怎么做（利用bitmap放入[redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)）

无限抛硬币,一正一反A赢,两反B赢,求A赢概率

电脑有仅1G内存，如何在[海量数据](https://www.nowcoder.com/jump/super-jump/word?word=海量数据)中快速找到100个目标数据？（[海量数据](https://www.nowcoder.com/jump/super-jump/word?word=海量数据)可能有序，也可能无序）【分块处理->块内[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)】

# 相关参考链接

> https://blog.csdn.net/v_july_v/article/details/6685962