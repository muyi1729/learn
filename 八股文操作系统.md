OS不是运行着的代码，而是一堆躺在内存里等着被调用的代码



进程切换是当前进程调用schdule()

```
在大部分情况下，我们认为内核态是一种CPU的特权态，这个特权态下，CPU可以执行这个特权态才允许执行的指令，访问这个特权态才运行访问的资源。这和当前的进程无关。OS通过控制不同的特权态来控制资源分配。一般有两种方法切换特权态，一种是特殊的指令，比如x86的软中断指令，或者大部分RISC系统的系统调用指令（比如SC），第二种是执行异常或者外部中断。发生切换后，现在到底是哪个进程，其实是无所谓的。现在说说现代LINUX如何定义线程和进程。我倾向于这样解释线程和进程:线程本质就是堆栈，当一段程序在执行，能代表它的是他的过去和现在。"过去"在堆栈中，"现在"则是CPU的所有寄存器，如果我们要挂起一个线程，我们把寄存器也保存到堆栈中，我们就具有它的所有状态，可以随时恢复它。这是线程。当我们切换线程的时候，同时切换它的地址空间（通过修改MMU即可），则我们认为发生了进程切换。所以进程的本质是地址空间，我们可以认为地址空间决定了进程是否发生切换。回到最初的问题，当CPU的特权级刚刚发生切换的时候，显然和进程，线程的切换是无关的，但之后调度器是否切换线程和进程，则和具体的情形相关了。
```



# 1、进程、线程和协程的区别和联系

|          |                             进程                             |                        线程                        |                             协程                             |
| -------- | :----------------------------------------------------------: | :------------------------------------------------: | :----------------------------------------------------------: |
| 定义     |                      资源分配的最小单位                      |                 CPU调度的最小单位                  |          用户态的轻量级线程，线程内部调度的基本单位          |
| 切换情况 | 旧进程CPU环境的保存(栈、寄存器、页表)以及新进行CPU环境的设置 |     保存和设置程序计数器、少量寄存器和栈的内容     |     先将寄存器上下文和栈保存，等切换回来的时候再进行恢复     |
| 切换者   |                           操作系统                           |                      操作系统                      |                             用户                             |
| 切换过程 |                    用户态->内核态->用户态                    |               用户态->内核态->用户态               |                     用户态(没有陷入内核)                     |
| 调用栈   |                            内核栈                            |                       内核栈                       |                            用户栈                            |
| 拥有资源 |             CPU资源、内存资源、文件资源和句柄等              |           程序计数器、寄存器、栈和状态字           |                  拥有自己的寄存器上下文和栈                  |
| 并发性   |        不同进程之间切换实现并发，各自占有CPU实现并行         |           一个进程内部的多个线程并发执行           | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 |  切换时只需保存和设置少量寄存器内容，因此开销很小  | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| 通信方面 |                  进程间通信需要借助操作系统                  | 线程间可以直接读写进程数据段(如全局变量)来进行通信 |                      共享内存、消息队列                      |

- 进程是资源调度的基本单位，是资源分配的最小单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序
- 线程是程序执行的基本单位，是CPU调度的最小单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。
- Linux 中进程和线程实际上都是用一个结构体 `task_struct`来表示一个执行任务的实体。进程创建调用`fork` 系统调用，而线程创建则是 `pthread_create` 方法，但是这两个方法最终都会调用到 `do_fork` 来做具体的创建操作 ，区别就在于传入的参数不同。linux 实现线程的方式简直太巧妙了，实际上根本没有**线程**，它创建的就是进程，只不过通过参数指定多个线程之间共享某些资源（如虚拟内存、页表、文件描述符等），函数调用栈、寄存器等线程私有数据则独立。
- 同一进程内的多个线程共享该进程的资源，但线程并不拥有资源，只是使用他们。
- 但是在其它提供了专门线程支持的系统中，则会在进程控制块（PCB）中增加一个包含指向该进程所有线程的指针，然后在每个线程中再去包含自己独占的资源。这算是非常正统的实现方式了，比如 Windows 就是这样干的。
- 多提一句：协程是用户态的轻量级线程，线程内部调度的基本单位

> 维基百科对于协程的定义：https://zh.wikipedia.org/wiki/%E5%8D%8F%E7%A8%8B
>
> 官方定义：A coroutine is a **function** that can **suspend** its execution (yield) until the given given **YieldInstruction** finishes.

**另一篇博客的总结：**

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210317110139.png)

- 进程是资源分配的最小单位，会拥有独立的地址空间以及对应的内存空间，还有网络和文件资源等，不同进程之间资源都是独立的，可以通过进程间通信（管道、共享内存、信号量等方式）来进行交互。
- 线程为CPU调度的基本单位，除了拥有运行中必不可少的信息(如程序计数器、一组寄存器和栈)以外，本身并不拥有系统资源，所有线程会共享进程的资源，比如会共享堆资源。
- 协程可以认为是运行在线程上的代码块，协程提供的挂起操作会使协程暂停执行，而不会导致线程阻塞。一个线程内部可以创建几千个协程都没有任何问题。
- 进程的切换和线程切换中都包含了对应上下文的切换，这块都涉及到了内核来完成，即一次用户态到内核态的切换和一次内核态到用户态的切换。因为进程上下文切换保存的信息更多，所以进程切换代价会比线程切换代价更大。
- 协程是一个纯用户态的并发机制，同一时刻只会有一个协程在运行，其他协程挂起等待；不同协程之间的切换不涉及内核，只用在用户态切换即可，所以切换代价更小，更轻量级，适合IO密集型的场景。



# 2、进程切换步骤

- 保存处理器上下文环境（包括程序计数器和其它寄存器）
- 更新当前处于运行态进程的进程控制块（状态和其它信息）
- 将进程控制块移到相应队列
- 选择另一个进程执行
- 更新所选择进程的进程控制块（包括将状态变为运行态）
- 更新内存管理的数据结构
- 恢复处理器在被选择的进程最近一次切换出运行状态时的上下文环境

进程切换要保存上下文信息，主要包括：

通用目的寄存器
浮点寄存器
程序计数器
用户栈
状态寄存器
内核栈
各种内核数据结构：比如描绘地址空间的页表，包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。

# 3、进程与线程的比较，什么时候用多进程，什么时候用多线程

- 地址空间：同一进程的线程共享本进程的地址空间，而进程之间则是独立的地址空间
- 资源拥有：同一进程内的线程共享本进程的资源如内存、I/O、cpu等，但是进程之间的资源是独立的
- 一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮
- 进程切换时，消耗的资源大，效率高。所以涉及到频繁的切换时，使用线程要好于进程

多进程的意义：

- 优点：
  - 每个进程互相独立，不影响主程序的稳定性，子进程崩溃没关系
  - 通过增加CPU，就可以容易扩充性能
  - 可以尽量减少线程加锁/解锁的影响，极大提高性能
  - 每个子进程都有2GB地址空间和相关资源，总体能够达到的性能上限非常大

- 缺点：
  - 逻辑控制复杂，需要和主程序交互
  - 需要跨进程边界
  - 最好是多进程和多线程结合，即根据实际的需要

多线程的意义：

- 优点：
  - 能适当提高程序的执行效率
  - 能适当提高资源的利用率（CPU，内存）
  - 线程上的任务执行完成后，线程会自动销毁
- 无需跨进程边界
  
- 缺点：
  - 开启线程需要占用一定的内存空间（默认情况下，每一个线程都占 512 KB）
  - 如果开启大量的线程，会占用大量的内存空间，降低程序的性能
  - 线程越多，CPU 在调用线程上的开销就越大
  - 程序设计更加复杂，比如线程间的通信、多线程的数据共享

多进程可以使得系统鲁棒性更高，出错的时候容易找到错误的地方，而且不影响别的进程。多线程可以进行快速创建和数据共享，进程创建的开销很大，上下文切换开销也稍微大一些，频繁创建进程去响应服务器的请求会造成极大的开销，而且会增加响应时间，所以在进行服务器响应的时候会采用多线程。

使用地方：

​	多进程：安全以及独立的应用场景

​	多线程：I/O密集以及追求响应速度的

# 4、一个进程可以创建多少线程，和什么有关？

进程创建线程数量与一个线程所需空间以及虚拟内存大小有关。

- Linux 32 位系统：

  有4G虚拟内存，其中3G为用户空间。ulimit -s 可以查看线程栈大小，一般为10M或8M，因此一个进程大概可以创建300个线程。

- Windows下：

  一个进程可用虚拟空间是2G，默认情况下，线程的栈的大小是1MB，所以理论上最多只能创建2048个线程。如果要创建多于2048的话，必须修改编译器的设置。

因此，一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定，只要虚拟空间足够，那么新线程的建立就会成功。一般情况下，不需要那么多的线程。过多的线程将会导致大量的时间浪费在线程切换上，给程序运行效率带来负面影响。

# 5、外中断和异常有什么区别？

中断是指CPU对系统发生某件事时的一种响应：CPU 暂停正在执行的程序，在保留现场后自动地转去执行该事件的中断处理程序；执行完后，再返回到原程序的断点处继续执行。

- 外中断—指由于外部设备事件引起的中断（I/O中断，时钟中断，控制台中断）
- 异常—CPU内部事件引起的中断（非法指令，地址越界、算术溢出、**系统调用、页错误/页故障**）
- 异常是由执行了现行指令所引起的，中断与现行指令无关

引入原因：

- 外中断：为了支持CPU和设备间的并行操作
- 异常：处理CPU执行指令时本身出现的问题

|       类别        | 原因              | 异步/同步 | 返回行为         |
| :---------------: | ----------------- | --------- | ---------------- |
| 中断（interrupt） | I/O或其他硬件设备 | 异步      | 返回到下一条指令 |
|     陷入Trap      | 有意识安排的      | 同步      | 返回到下一条指令 |
|     故障Fault     | 可恢复的错误      | 同步      | 返回到当前指令   |
|     终止Abort     | 不可恢复的错误    | 同步      | 不会返回         |

# 6、进程线程模型你知道多少？

Linux 进程通过一个 task_struct 结构体描述，在 linux/sched.h 中定义，通过理解该结构，可更清楚的理解linux进程模型。  

```text
进程状态（State）
进程调度信息（Scheduling Information）
各种标识符（Identifiers）
进程通信有关信息（IPC：Inter_Process Communication）
时间和定时器信息（Times and Timers）
进程链接信息（Links）
文件系统信息（File System）
虚拟内存信息（Virtual Memory）
页面管理信息（page）
对称多处理器（SMP）信息
和处理器相关的环境（上下文）信息（Processor Specific Context）
其它信息
```

- 进程状态：可运行、可中断的等待状态、不可中断的等待状态、僵死、暂停、换入/换出
- 进程调度信息：调度程序利用这部分信息决定系统中哪个进程最应该运行，并结合进程的状态信息保证系统运转的公平和高效。这一部分信息通常包括进程的类别（普通进程还是实时进程）、进程的优先级等。
- 标识符：  每个进程有进程标识符、用户标识符、组标识符用以区分不同进程
- IPC:为了使进程能在同一项任务上协调工作，进程之间必须能进行通信即交流数据
- 进程链接信息：记录该进程的父、子、兄、祖父等信息
- 时间和定时器信息：一个进程从创建到终止叫做该进程的生存期（lifetime）。进程在其生存期内使用CPU的时间，内核都要进行记录，以便进行统计、计费等有关操作。
- 文件系统信息：进程可以打开或关闭文件，文件属于系统资源，Linux内核要对进程使用文件的情况进行记录。
- 虚拟内存信息：除了内核线程（kernel thread），每个进程都拥有自己的地址空间（也叫虚拟空间），用mm_struct来描述。
- 页面管理信息：记录换页信息
- 进程内核栈及current宏：记录进行在内核中的栈 以及 当前进程的指针描述符

（1）**多线程**

这里讨论的是用户态的多线程模型，同一个进程内部有多个线程，所有的线程共享同一个进程的内存空间，进程中定义的全局变量会被所有的线程共享，比如有全局变量int i = 10，这一进程中所有并发运行的线程都可以读取和修改这个i的值，而多个线程被CPU调度的顺序又是不可控的，所以对临界资源的访问尤其需要注意安全。

我们必须知道，**做一次简单的i = i + 1在计算机中并不是原子操作，涉及内存取数，计算和写入内存几个环节，**而线程的切换有可能发生在上述任何一个环节中间，所以不同的操作顺序很有可能带来意想不到的结果。

但是，虽然线程在安全性方面会引入许多新挑战，但是线程带来的好处也是有目共睹的。首先，原先顺序执行的程序（暂时不考虑多进程）可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务（最好这些任务是不相关的）。

比如 QQ 可以一个线程处理聊天一个线程处理上传文件，两个线程互不干涉，在用户看来是同步在执行两个任务，试想如果线性完成这个任务的话，在数据传输完成之前用户聊天被一直阻塞会是多么尴尬的情况。

对于线程，弄清以下两点非常重要：

- 线程之间有无先后访问顺序（线程依赖关系）
- 多个线程共享访问同一变量（同步互斥问题）

另外，通常只会去说同一进程的多个线程共享进程的资源，但是每个线程特有的部分却很少提及，除了标识线程的tid，每个线程还有自己独立的栈空间，线程彼此之间是无法访问其他线程栈上内容的。

而作为处理机调度的最小单位，线程调度只需要保存线程栈、寄存器数据和PC即可，相比进程切换开销要小很多。

线程相关接口不少，主要需要了解各个参数意义和返回值意义。

a.线程创建和结束

- 背景知识：

  在一个文件内的多个函数通常都是按照main函数中出现的顺序来执行，但是在分时系统下，我们可以让每个函数都作为一个逻辑流并发执行，最简单的方式就是采用多线程策略。在main函数中调用多线程接口创建线程，每个线程对应特定的函数（操作），这样就可以不按照main函数中各个函数出现的顺序来执行，避免了忙等的情况。线程基本操作的接口如下。

- 相关接口：

  - 创建线程：

    ```cpp
    int pthread_create(pthread_t *pthread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *agr);
    ```

    创建一个新线程，pthread 和 start_routine 不可或缺，分别用于标识线程和执行体入口，其他可以填 NULL。

    - pthread：用来返回线程的tid，*pthread值即为tid，类型pthread_t == unsigned long int。
    - attr：指向线程属性结构体的指针，用于改变所创线程的属性，填NULL使用默认值。
    - start_routine：线程执行函数的首地址，传入函数指针。
    - arg：通过地址传递来传递函数参数，这里是无符号类型指针，可以传任意类型变量的地址，在被传入函数中先强制类型转换成所需类型即可。

  - 获得线程ID：

    ```cpp
    pthread_t pthread_self();
    ```

    调用时，会打印线程ID。

  - 等待线程结束：

    ```cpp
    int pthread_join(pthread_t tid, void** retval);
    ```

    主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。

    - tid：创建线程时通过指针得到tid值。
    - retval：指向返回值的指针。

  - 结束线程：

    ```cpp
    pthread_exit(void *retval);
    ```

    子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。

    - retval：同上。

  - 分离线程：

    ```cpp
    int pthread_detach(pthread_t tid);
    ```

    主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。

b.线程属性值修改

- 背景知识：

  线程属性对象类型为 pthread_attr_t，结构体定义如下：

  ```cpp
  typedef struct{
      int etachstate;    // 线程分离的状态
      int schedpolicy;    // 线程调度策略
      struct sched_param schedparam;    // 线程的调度参数
      int inheritsched;    // 线程的继承性
      int scope;    // 线程的作用域
      // 以下为线程栈的设置
      size_t guardsize;    // 线程栈末尾警戒缓冲大小
      int stackaddr_set;    // 线程的栈设置
      void *    stackaddr;    // 线程栈的位置
      size_t stacksize;    // 线程栈大小
  }pthread_arrt_t;
  ```

- 相关接口：

  对上述结构体中各参数大多有：pthread_attr_get()和pthread_attr_set()系统调用函数来设置和获取。这里不一一罗列。

**（2）多进程**

进程地址空间由以下几个部分组成：代码段、堆栈段、数据段。代码段是静态的二进制代码，多个程序可以共享。

实际上在父进程创建子进程之后，父、子进程除了pid外，几乎所有的部分几乎一样。

父、子进程共享全部数据，但并不是说他们就是对同一块数据进行操作，子进程在读写数据时会通过写时复制机制将公共的数据重新拷贝一份，之后在拷贝出的数据上进行操作。

如果子进程想要运行自己的代码段，还可以通过调用execv()函数重新加载新的代码段，之后就和父进程独立开了。

我们在shell中执行程序就是通过shell进程先fork()一个子进程再通过execv()重新加载新的代码段的过程。

1. 进程创建与结束

   - 背景知识：

     进程有两种创建方式，一种是操作系统创建的一种是父进程创建的。从计算机启动到终端执行程序的过程为：0号进程 -> 1号内核进程 -> 1号用户进程(init进程) -> getty进程 -> shell进程 -> 命令行执行进程。所以我们在命令行中通过 ./program执行可执行文件时，所有创建的进程都是shell进程的子进程，这也就是为什么shell一关闭，在shell中执行的进程都自动被关闭的原因。从shell进程到创建其他子进程需要通过以下接口。

   - 相关接口：

     - 创建进程：

       ```cpp
       pid_t fork(void);
       ```

       返回值：出错返回-1；父进程中返回pid > 0；子进程中pid = 0

     - 结束进程：

       ```cpp
       void exit(int status);
       ```

       status是退出状态，保存在全局变量中，通常0表示正常退出。

     - 获得PID：

       ```cpp
       pid_t getpid(void);
       ```

       返回调用者pid。

     - 获得父进程PID：

       ```cpp
       pid_t getppid(void);
       ```

       返回父进程pid。

   - 其他补充：

     - 正常退出方式：exit()、_exit()、return（在main中）。

       exit()和_ exit()区别：exit()是对 _ exit()的封装，都会终止进程并做相关收尾工作，最主要的区别是 _ exit()函数关闭全部描述符和清理函数后不会刷新流，但是exit()会在调用_exit()函数前刷新数据流。

       return和exit()区别：exit()是函数，但有参数，执行完之后控制权交给系统。return若是在调用函数中，执行完之后控制权交给调用进程，若是在main函数中，控制权交给系统。

     - 异常退出方式：abort()、终止信号。

2. Linux进程控制

- 进程地址空间（地址空间）

  虚拟存储器为每个进程提供了独占系统地址空间的假象。

  尽管每个进程地址空间内容不尽相同，但是他们的都有相似的结构。X86 Linux进程的地址空间底部是保留给用户程序的，包括文本、数据、堆、栈等，其中文本区和数据区是通过存储器映射方式将磁盘中可执行文件的相应段映射至虚拟存储器地址空间中。

  有一些"敏感"的地址需要注意下，对于32位进程来说，代码段从0x08048000开始。从0xC0000000开始到0xFFFFFFFF是内核地址空间，通常情况下代码运行在用户态（使用0x00000000 ~ 0xC00000000的用户地址空间），当发生系统调用、进程切换等操作时CPU控制寄存器设置模式位，进入内核模式，在该状态（超级用户模式）下进程可以访问全部存储器位置和执行全部指令。

  也就说32位进程的地址空间都是4G，但用户态下只能访问低3G的地址空间，若要访问3G ~ 4G的地址空间则只有进入内核态才行。

- 进程控制块（处理机）

  进程的调度实际就是内核选择相应的进程控制块，被选择的进程控制块中包含了一个进程基本的信息。

- 上下文切换

  内核管理所有进程控制块，而进程控制块记录了进程全部状态信息。每一次进程调度就是一次上下文切换，所谓的上下文本质上就是当前运行状态，主要包括通用寄存器、浮点寄存器、状态寄存器、程序计数器、用户栈和内核数据结构（页表、进程表、文件表）等。

  进程执行时刻，内核可以决定抢占当前进程并开始新的进程，这个过程由内核调度器完成，当调度器选择了某个进程时称为该进程被调度，该过程通过上下文切换来改变当前状态。

  一次完整的上下文切换通常是进程原先运行于用户态，之后因系统调用或时间片到切换到内核态执行内核指令，完成上下文切换后回到用户态，此时已经切换到进程B。

# 7、进程调度算法你了解多少？

- **先来先服务 first-come first-serverd（FCFS）**

   从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

  非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

- **短作业优先 shortest job first（SJF）**

  从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

  非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

- **最短剩余时间优先 shortest remaining time next（SRTN）**

  最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

- **时间片轮转**

  又称 RR(Round robin)调度，每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

  时间片轮转算法的效率和时间片的大小有很大关系：

  - 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
  - 而如果时间片过长，那么实时性就不能得到保证。

- **优先级调度**

  为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

- **多级反馈队列**

  多级反馈队列算法，不必事先知道各种进程所需要执行的时间，他是当前被公认的一种较好的进程调度算法。其实施过程如下：

  - 设置多个就绪队列，并为各个队列赋予不同的优先级。在优先权越高的队列中，为每个进程所规定的执行时间片就越小。
  - 当一个新进程进入内存后，首先放入第一队列的末尾，按照先来先去原则排队等候调度。如果他能在一个时间片中完成，便可撤离；如果未完成，就转入第二队列的末尾，同样等待调度.....如此下去，当一个长作业（进程）从第一队列依次将到第n队列（最后队列）后，便按第n队列时间片轮转运行。
  - 仅当第一队列空闲的时候，调度程序才调度第二队列中的进程运行；仅当第1到（i-1）队列空时，才会调度第i队列中的进程运行，并执行相应的时间片轮转。
  - 如果处理机正在处理第i队列中某进程，又有新进程进入优先权较高的队列，则此新队列抢占正在运行的处理机，并把正在运行的进程放在第i队列的队尾。

  可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

- **最高响应比优先**

  根据比率：R=(w+s)/s （R为响应比，w为等待处理的时间，s为预计的服务时间）

  如果该进程被立即调用，则R值等于归一化周转时间（周转时间和服务时间的比率）。R最小值为1.0，只有第一个进入系统的进程才能达到该值。调度规则为：当前进程完成或被阻塞时，选择R值最大的就绪进程，它说明了进程的年龄。当偏向短作业时，长进程由于得不到服务，等待时间不断增加，从而增加比值，最终在竞争中赢了短进程。

  和最短进程优先、最短剩余时间优先一样，使用最高响应比策略需要估计预计服务时间。

# 8、Linux下进程通信方式？

进程间通信（Inter Process Communication），指的是不同进程间进行交流，本质上就是进程之间发送和接收数据。内核的1G空间的共享特性给进程间通信带来可能。

（1）管道

管道大小默认为4K

- 无名管道（虚拟的FIFO文件）

  ```cpp
  int pipe(int pipefe[2])// [0]读  [1]写
  ```

  这两个分别用于读写的描述符必须同时打开才行，否则会出问题。
  管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用。进程的亲缘关系通常是指父子进程关系。

- 有名管道（实际的FIFO文件）

  ```cpp
  int mkfifo(const char *pathname, mode_t mode);//建立有名管道文件
  ```

  不同于匿名管道之处在于它提供一个路径名与之关联，以FIFO的文件形式存在于文件系统中。这样，即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过FIFO相互通信（能够访问该路径的进程以及FIFO的创建进程之间），因此，通过FIFO不相关的进程也能交换数据。值得注意的是，FIFO严格遵循先进先出（first in first out），对管道及FIFO的读总是从开始处返回数据，对它们的写则把数据添加到末尾。

（2）共享内存

```c++
int shmget(key_t key, size_t size, int shmflg)//依据key获取内核对象id，并设置size字节大小
void *shmat(int shmid, const void *shmaddr, int shmflg)//连接共享内存标识符为shmid的共享内存，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问
int shmdt(const void *shmaddr)//与shmat相反
int shmctl(int shmid, int cmd, struct shmid_ds *buf)//控制共享内存
```

- 共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。如果某个进程向共享内存内写入数据，所做的改动将立即影响到可以访问该共享内存的其他所有进程。
- 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。
- 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
- 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

（3）消息队列

消息队列本质上是位于内核空间的链表，存放在内核中并由消息队列标识符标识。链表的每个节点都是一条消息，每一条消息都有自己的消息类型。消息类型用整数来表示，而且必须大于 0。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

与命名管道相比：消息队列的优势在于，它独立于发送和接收进程而存在，这消除了在同步命名管道的打开和关闭时可能产生的一些困难。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。而且，每个数据块被认为含有一个类型，接收进程可以独立地接收含有不同类型值的数据块。

```c++
// 创建和获取 ipc 内核对象
int msgget(key_t key, int flags);
// 将消息发送到消息队列
int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg);
// 从消息队列获取消息
ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg);
// 查看、设置、删除 ipc 内核对象（用法和 shmctl 一样）
int msgctl(int msqid, int cmd, struct msqid_ds *buf);
```

（4）信号量

主要作为进程间以及同一进程不同线程之间的同步手段。

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

```c++
//POSIX相比于System V要新一些且简单一些
//System V：
int semget(key_t key, int nsems, int semflg);
int semop(int semid, struct sembuf *sops, unsigned nsops);
int semctl(int semid, int semnum, int cmd);
int semctl(int semid, int semnum, int cmd, union semun buf);
```

（5）信号

信号是一种比较复杂的通信方式，信号产生的条件：按键、硬件异常、进程调用kill函数将信号发送给另一个进程、用户调用kill命令将信号发送给其他进程，信号传递的消息比较少，主要用于通知接收进程某个事件已经发生。

```text
Ctrl + C (相当于发送信号 2， SIGINT)   
Ctrl + Z (相当于发送信号 20， SIGTSTP) 
Ctrl + \ (相当于发送信号 3，SIGQUIT)
子进程结束给父进程 发送 SIGCHLD
SIGKILL 和 SIGSTOP无法被捕获
1-32是不可靠信号 32-64是实时信号 不可靠信号会合并
```

```c++
sighandler_t signal(int signum, sighandler_t handler);//向内核注册处理 signum 的处理函数
int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);//在处理某一信号时
//可以阻塞其他信号
```

可重入函数是线程安全函数的子集（不访问任何全局变量或静态变量）

（6）套接字

更为一般的进程间通信机制，适用于不同机器间进程通信，在本地也可作为两个进程通信的方式。

# 9、Linux 下同步机制

- 进程间同步：信号量


- 线程间同步：读写锁、互斥锁、信号量、条件变量、屏障


# 10、如果系统中具有快表后、那么地址的转换过程变成了什么？

- CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较
- 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表命中，则访问某个逻辑地址仅需一次访存即可
- 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表未命中，则访问某个逻辑地址需要两次访存（注意：在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换)

由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。 因为局部性原理，一般来说快表的命中率可以达到90%以上。

# 11、内存交换和覆盖有什么区别？

**覆盖**和**交换技术**是在多道程序环境下用来**扩充内存**的两种方法。

**覆盖技术**主要用在早期的操作系统中，而**交换**技术则在现代操作系统中仍具有较强的生命力。

- 覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序）， 因此可以把用户空间分成**一个固定区**和**若干个覆盖区**。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些**即将要访问**的段放入**覆盖区**，其他段放在**外存**中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。

  覆盖技术的实现是把程序划分为若干个**功能上相对独立的程序段**，按照其自身的逻辑结构使那些**不会同时运行的程序段**共享同一块内存区域。程序段先保存在磁盘上，当有关程序的前一部分执行结束后，把后续程序段调入内存，覆盖前面的程序段。

  覆盖技术的特点：是打破了必须将一个进程的全部信息装入内存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，再而，大家要注意到，内存中能够更新的地方只有覆盖区的段，不在覆盖区的段会常驻内存。

- 交换（对换）的基本思想是：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)

  换入：把准备好竞争CPU运行的程序从辅存移到内存。换出：把处于**等待（阻塞）**状态（或在CPU调度原则下被剥夺运行权利）的程序（进程）从内存移到辅存（外存），把内存空间腾出来。

  **什么时候会进行内存的交换？**

  内存交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；如果缺页率明显下降，就可以暂停换出。

交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中。

> 内存覆盖和内存交换：https://blog.csdn.net/dongyanxia1000/article/details/51425141

# 12、动态分区分配算法有哪几种？可以分别说说吗？

**（1）首次适应算法**

算法思想：每次都从低地址开始查找，找到第–个能满足大小的空闲分区。

如何实现：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319151550.png)

**（2）最佳适应算法**

算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。

如何实现：空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319151730.png)

**（3）最坏适应算法**

又称最大适应算法(Largest Fit)

算法思想：为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。

如何实现：空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319151910.png)

（4）邻近适应算法

算法思想：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

如何实现：空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319152053.png)

**（5）总结**

首次适应不仅最简单，通常也是最好最快，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。

最佳导致大量碎片，最坏导致没有大的空间。

进过实验，首次适应比最佳适应要好，他们都比最坏好。

| 算法     | 算法思想                                           | 分区排列顺序                                 | 优点                                                         | 缺点                                                         |
| -------- | -------------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 首次适应 | 从头到尾找适合的分区                               | 空闲分区以地址递增次序排列                   | 综合看性能最好。**算法开销小**，回收分区后一.般不需要对空闲分区队列重新排序 |                                                              |
| 最佳适应 | 优先使用更小的分区，以保留更多大分区               | 空闲分区以容量递增次序排列                   | 会有更多的大分区被保留下来，更能满足大进程需求               | 会产生很多太小的、难以利用的碎片;**算法开销大**，回收分区后可能需要对空闲分区队列重新排序 |
| 最坏适应 | 优先使用更大的分区，以防止产生太小的不可用的碎片   | 空闲分区以容量递减次序排列                   | 可以减少难以利用的小碎片                                     | 大分区容易被用完，不利于大进程;**算法开销大**(原因同上)      |
| 邻近适应 | 由首次适应演变而来，每次从上次查找结束位置开始查找 | 空闲分区以地址递增次序排列(可排列成循环链表) | 不用每次都从低地址的小分区开始检索。**算法开销小**(原因同首次适应算法) | 会使高地址的大分区也被用完                                   |

# 13、虚拟技术你了解吗？

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多进程与多线程：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

# 14、进程状态的切换你知道多少？

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319152622.png)

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

# 15、通过例子讲解逻辑地址转换为物理地址的基本过程

可以借助进程的页表将逻辑地址转换为物理地址。

通常会在系统中设置一个页表寄存器(PTR)，存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块(PCB) 中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

注意:页面大小是2的整数幂 设页面大小为L，逻辑地址A到物理地址E的变换过程如下:

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319153408.png)

例：若页面大小L为1K字节，页号2对应的内存块号b=8，将逻辑地址A=2500转换为物理地址E。 等价描述：某系统按字节寻址，逻辑地址结构中，页内偏移量占10位(说明一个页面的大小为2^10B = 1KB)，页号2对应的内存块号 b=8，将逻辑地址A=2500转换为物理地址E。

- 计算页号、页内偏移量 页号P=A/L = 2500/1024 = 2; 页内偏移量W= A%L = 2500%1024 = 452
- 根据题中条件可知，页号2没有越界，其存放的内存块号b=8
- 物理地址E=b*L+W=8 * 1024+ 425 = 8644

在分页存储管理(页式管理)的系统中，只要确定了每个页面的大小，逻辑地址结构就确定了。因此，页式管理中地址是-维的。即，只要给出一个逻辑地址，系统就可以自动地算出页号、页内偏移量两个部分，并不需要显式地告诉系统这个逻辑地址中，页内偏移量占多少位。

# 16、进程同步的四种方法？

（1） 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```cpp
// entry section
// critical section;
// exit section
```

（2）同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系
- 互斥：多个进程在同一时刻只有一个进程能进入临界区

（3）信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，如果信号量为0，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```cpp
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

**使用信号量实现生产者-消费者问题**

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。

其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

**注意**，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。

消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```cpp
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

（4）管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```pascal
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

**使用管程实现生产者-消费者问题**

```pascal
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

# 17、操作系统在对内存进行管理的时候需要做些什么?

- 操作系统负责内存空间的分配与回收。
- 操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
- 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
- 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰

# 18、进程通信方法和线程通信方法

（1）**进程通信方法**

| 名称及方式                                                   |
| ------------------------------------------------------------ |
| 管道(pipe)：允许一个进程和另一个与它有共同祖先的进程之间进行通信 |
| 命名管道(FIFO)：类似于管道，但是它可以用于任何两个进程之间的通信，命名管道在文件系统中有对应的文件名。命名管道通过命令mkfifo或系统调用mkfifo来创建 |
| 消息队列(MQ)：消息队列是消息的连接表，包括POSIX消息对列和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点； |
| 信号量(semaphore)：信号量主要作为进程间以及同进程不同线程之间的同步手段； |
| 共享内存(shared memory)：它使得多个进程可以访问同一块内存空间，**是最快的可用IPC形式。**这是针对其他通信机制运行效率较低而设计的。它往往与其他通信机制，如信号量结合使用，以达到进程间的同步及互斥 |
| 信号(signal)：信号是比较复杂的通信方式，用于通知接收进程有某种事情发生，除了用于进程间通信外，进程还可以发送信号给进程本身 |
| 内存映射(mapped memory)：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它 |
| Socket：它是更为通用的进程间通信机制，可用于不同机器之间的进程间通信 |

（2）**线程通信方法**

| 信号：类似进程间的信号处理                     |
| ---------------------------------------------- |
| 锁机制：互斥锁、读写锁和自旋锁                 |
| 条件变量：使用通知的方式解锁，与互斥锁配合使用 |
| 信号量：包括无名线程信号量和命名线程信号量     |

# 19、虚拟内存的目的是什么？

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。

这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，并通过页面置换，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319161113.png)

# 20、说一下你理解中的内存？他有什么作用呢？

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319162217.png)

# 21、操作系统经典问题之哲学家进餐问题

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319162307.png)

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```cpp
#define N 5
void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```cpp
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(LEFT); 
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```

# 22、操作系统经典问题之读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```cpp
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);//最后一个读者要对数据进行解锁，防止写进程无法访问
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

# 23、介绍一下几种典型的锁

（1）**读写锁**

- 多个读者可以同时进行读
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）

（2）**互斥锁**

一次只能一个线程拥有互斥锁，其他线程只有等待

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不如使用自旋锁

互斥锁属于sleep-waiting类型的锁。例如在一个双核的机器上有两个线程A和B，它们分别运行在core 0和core 1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，此时会通过上下文切换将线程A置于等待队列中，此时core 0就可以运行其他的任务（如线程C）。

**条件变量**

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说**互斥锁是线程间互斥的机制，条件变量则是同步机制**。

（3）**自旋锁**

如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

自旋锁属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，如果自旋锁已经被线程B所持有，那么线程A就会一直在core 0上进行忙等待并不停的进行锁请求，检查该自旋锁是否已经被线程B释放，直到得到这个锁为止。因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远高于互斥锁。

虽然它的效率比互斥锁高，但是它也有些不足之处：

- 自旋锁一直占用CPU，在未获得锁的情况下，一直进行自旋，所以占用着CPU，如果不能在很短的时间内获得锁，无疑会使CPU效率降低。
- 在用自旋锁时有可能造成死锁，当递归调用时有可能造成死锁。

自旋锁只有在内核可抢占式或SMP（多CPU）的情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的操作为空操作。自旋锁适用于锁使用者保持锁时间比较短的情况下。

> 《互斥锁、读写锁、自旋锁、条件变量的特点总结》：https://blog.csdn.net/RUN32875094/article/details/80169978

# 24、逻辑地址VS物理地址

编译时只需确定变量 x 存放的相对地址是100 ( 也就是说相对于进程在内存中的起始地址而言的地址)。CPU想要找到 x 在内存中的实际存放位置，只需要用进程的起始地址+100即可。 相对地址又称逻辑地址，绝对地址又称物理地址。

# 25、怎么回收线程？有哪几种方法？

- 等待线程结束：

  ```cpp
  int pthread_join(pthread_t tid, void** retval);
  ```

  主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。

  - tid：创建线程时通过指针得到tid值。
  - retval：指向返回值的指针。

- 结束线程：

  ```cpp
  pthread_exit(void *retval);
  ```

  子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。

- 分离线程：

  ```cpp
  int pthread_detach(pthread_t tid);
  ```

  主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。

# 26、终端退出，终端运行的进程会怎样

终端在退出时会发送 SIGHUP 给对应的bash进程，bash进程收到这个信号后首先将它发给session下面的进程，如果程序没有对 SIGHUP 信号做特殊处理，那么进程就会随着终端关闭而退出。

> 《linux终端关闭时为什么会导致在其上启动的进程退出？》：https://blog.csdn.net/QFire/article/details/80112701

# 27、如何让进程后台运行

- 命令后面加上 & 即可，实际上，这样是将命令放入到一个作业队列中了
- ctrl + z 挂起进程，使用jobs查看序号，再使用bg %序号后台运行进程
- nohup + &，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断（SIGHUP）信号
- 运行指令前面 + setsid，使其父进程变成init进程，不受HUP信号的影响
- 将命令+ &放在()括号中，也可以是进程不受HUP信号的影响

# 28、什么是快表，你知道多少关于快表的知识？

快表，又称联想寄存器(TLB) ，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319170534.png)

# 29、地址变换中，有快表和没快表，有什么区别？

|                        |                         地址变换过程                         | 访问一个逻辑地址的访存次数                      |
| ---------------------- | :----------------------------------------------------------: | ----------------------------------------------- |
| 基本地址变换机构       | ①算页号、页内偏移量 ②检查页号合法性 ③查页表，找到页面存放的内存块号 ④根据内存块号与页内偏移量得到物理地址 ⑤访问目标内存单元 | 两次访存                                        |
| 具有快表的地址变换机构 | ①算页号、页内偏移量 ②检查页号合法性 ③查快表。若命中，即可知道页面存放的内存块号，可直接进行⑤；若未命中则进行 ④查页表，找到页面存放的内存块号，并且将页表项复制到快表中 ⑤根据内存块号与页内偏移量得到物理地址 ⑥访问目标内存单元 | 快表命中，只需一次访存 快表未命中，需要两次访存 |

# 30、 守护进程、僵尸进程和孤儿进程

**（1）守护进程**

指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等。

创建守护进程要点：

- 让程序在后台执行。方法是调用 fork() 产生一个子进程，然后使父进程退出。
- 调用 setsid() 创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid() 使进程成为一个会话组长。setsid() 调用成功后，进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。
- 禁止进程重新打开控制终端。经过以上步骤，进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过fork()创建新的子进程，使调用fork的进程退出。
- 关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符。
- 将当前目录更改为根目录。
- 子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，使用unmask（0）将屏蔽字清零。
- 处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程（zombie），从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，子进程结束时不会产生僵尸进程。

**（2）孤儿进程**

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。（注：任何一个进程都必须有父进程）。

**（3）僵尸进程**

如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。

设置**僵尸进程的目**的是维护子进程的退出信息，以便父进程在以后某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用 wait 或 waitpid 时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）。

# 31、如何避免僵尸进程？

- 通过 signal(SIGCHLD, SIG_IGN) 通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN)；表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。
- 父进程调用 wait/waitpid 等函数等待子进程结束，如果尚无子进程退出wait 会导致父进程阻塞。waitpid 可以通过传递 WNOHANG 使父进程不阻塞立即返回。
- 如果父进程很忙可以用 signal 注册信号处理函数，在信号处理函数调用wait/waitpid 等待子进程退出。
- 通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，孙进程结束后，init会等待回收。

第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。

> 《Linux系统下创建守护进程(Daemon)》：https://blog.csdn.net/linkedin_35878439/article/details/81288889
>
> 《01_fork()的使用》：https://blog.csdn.net/WUZHU2017/article/details/81636851

# 32、局部性原理你知道吗？主要有哪两大局部性原理？各自是什么？

主要分为**时间局部性和空间局部性**。

时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环) 

空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210319173634.png)

# 33、父进程、子进程、进程组、作业和会话

**（1）父进程**

已创建一个或多个子进程的进程

**（2）子进程**

由fork创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程id返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程id。对子进程来说，之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid；也可以调用getppid()来获取父进程的id。(进程id 0总是由交换进程使用，所以一个子进程的进程id不可能为0 )。

fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数器pc值相同，也就是说，子进程是从fork返回处开始执行的），但有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。

子进程从父进程继承的有：

- 进程的资格(真实(real)/有效(effective)/已保存(saved)用户号(UIDs)和组号(GIDs))
- 环境(environment)
- 堆栈
- 内存
- 进程组号

独有：

- 进程号；
- 不同的父进程号(译者注：即子进程的父进程号与父进程的父进程号不同， 父进程号可由getppid函数得到)；
- 资源使用(resource utilizations)设定为0

**（3）进程组**

进程组就是多个进程的集合，其中肯定有一个组长，其进程PID等于进程组的PGID。只要在某个进程组中一个进程存在，该进程组就存在，这与其组长进程是否终止无关。

**（4）作业**

shell分前后台来控制的不是进程而是作业（job）或者进程组（Process Group）。

一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，shell可以运行一个前台作业和任意多个后台作业，这称为作业控制。

**为什么只能运行一个前台作业？** 答：当我们在前台新起了一个作业，shell就被提到了后台，因此shell就没有办法再继续接受我们的指令并且解析运行了。 但是如果前台进程退出了，shell就会有被提到前台来，就可以继续接受我们的命令并且解析运行。

作业与进程组的区别：如果作业中的某个进程创建了子进程，则该子进程是不属于该作业的。 一旦作业运行结束，shell就把自己提到前台（子进程还存在，但是子进程不属于作业），如果原来的前台进程还存在（这个子进程还没有终止），他将自动变为后台进程组

**（5）会话**

会话（Session）是一个或多个进程组的集合。一个会话可以有一个控制终端。在xshell或者WinSCP中打开一个窗口就是新建一个会话。

# 34、进程终止的几种方式

- main函数的自然返回，`return` 
- 调用`exit`函数，属于c的函数库 
- 调用`_exit`函数，属于系统调用 
- 调用`abort`函数，异常程序终止，同时发送SIGABRT信号给调用进程。
- 接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)

**exit和_exit的区别**

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321095631.png)

> 《学习笔记]进程终止的5种方式》：https://www.cnblogs.com/shichuan/p/4432503.html

# 35、Linux中异常和中断的区别

**中断**

大家都知道，当我们在敲击键盘的同时就会产生中断，当硬盘读写完数据之后也会产生中断，所以，我们需要知道，中断是由硬件设备产生的，而它们从物理上说就是电信号，之后，它们通过中断控制器发送给CPU，接着CPU判断收到的中断来自于哪个硬件设备（这定义在内核中），最后，由CPU发送给内核，由内核处理中断。下面这张图显示了中断处理的流程：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321095737.png)

**异常**

我们在学习《计算机组成原理》的时候会知道两个概念，CPU处理程序的时候一旦程序不在内存中，会产生缺页异常；当运行除法程序时，当除数为0时，又会产生除0异常。所以，大家也需要记住的是，**异常是由CPU产生的，同时，它会发送给内核，要求内核处理这些异常**，下面这张图显示了异常处理的流程：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321095903.png)

**相同点**

- 最后都是由CPU发送给内核，由内核去处理
- 处理程序的流程设计上是相似的

**不同点**

- 产生源不相同，异常是由CPU产生的，而中断是由硬件设备产生的
- 内核需要根据是异常还是中断调用不同的处理程序
- 中断不是时钟同步的，这意味着中断可能随时到来；异常由于是CPU产生的，所以它是时钟同步的
- 当处理中断时，处于**中断上下文**中；处理异常时，处于**进程上下文**中

> 《Linux内核--异常和中断的区别》：https://blog.csdn.net/u011068464/article/details/10284741

# 36、Linux环境下内存分布情况

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321100109.png)

通过这张图你可以看到，用户空间内存，从**低到高**分别是 7 种不同的内存段：

- 程序文件段，包括二进制可执行代码；
- 已初始化数据段，存储初始化的全局变量和初始化的 static 变量，包括静态常量；
- 未初始化数据段，存储未初始化的全局变量和未初始化的 static 变量
- 堆段，包括动态分配的内存，从低地址开始向上增长，堆的生存期随进程持续性，从 malloc/realloc 到 free 一直存在
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关）
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小。栈的生存期随代码块持续性，代码块运行就给你分配空间，代码块结束，就自动回收空间

# 37、一个由C/C++编译的程序占用的内存分为哪几个部分？

- 栈区（stack）— 地址向下增长，由编译器自动分配释放，存放函数的参数值，局部变量的值等
- 堆区（heap）— 地址向上增长，一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。
- 全局区（静态区）（static）—全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 程序结束后由系统释放
- 文字常量区 —常量字符串就是放在这里的。程序结束后由系统释放
- 程序代码区(text)—存放函数体的二进制代码。

# 38、一般情况下在Linux/windows平台下栈空间的大小

Linux环境下由操作系统决定，一般是8MB，8192kbytes，通过ulimit命令查看以及修改

Windows环境下由编译器决定，VC++6.0一般是1M

**Linux**

linux下非编译器决定栈大小，而是由操作系统环境决定，默认是8192KB（8M）；而在Windows平台下栈的大小是被记录在可执行文件中的（由编译器来设置)，即：windows下可以由编译器决定栈大小，而在Linux下是由系统环境变量来控制栈的大小的。

在Linux下通过如下命令可查看和设置栈的大小：

```
$ ulimit -a            # 显示当前栈的大小 （ulimit为系统命令，非编译器命令）       
$ ulimit -s 32768      # 设置当前栈的大小为32M
```

**Windows**

VC++ 6.0 默认的栈空间是1M。

VC6.0中修改堆栈大小的方法：

- 选择 "Project->Setting"
- 选择 "Link"
- 选择 "Category"中的 "Output"
- 在 "Stack allocations"中的"Reserve:"中输栈的大小

> 《Linux/windows栈大小》：https://blog.csdn.net/HQ354974212/article/details/76087676

# 39、程序从堆中动态分配内存时，虚拟内存上怎么操作的

页表：是一个存放在物理内存中的数据结构，它记录了虚拟页与物理页的映射关系

在进行动态内存分配时，例如malloc()函数或者其他高级语言中的new关键字，操作系统会在硬盘中创建或申请一段虚拟内存空间，并更新到页表（分配一个页表条目（PTE），使该PTE指向硬盘上这个新创建的虚拟页），通过PTE建立虚拟页和物理页的映射关系。

# 40、常见的几种磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

（1）先来先服务

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

（2） 最短寻道时间优先

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321101348.png)

（3）电梯扫描算法

电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321101530.png)

# 41、交换空间与虚拟内存的关系

**交换空间** 

Linux 中的交换空间（Swap space）在**物理内存**（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进入物理内存要慢。 交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。 交换空间的总大小应该相当于你的计算机内存的两倍和 32 MB这两个值中较大的一个，但是它不能超过 2048MB（2 GB）。 

**虚拟内存** 

虚拟内存是文件数据交叉链接的活动文件。是WINDOWS目录下的一个"WIN386.SWP"文件，这个文件会不断地扩大和自动缩小。 就速度方面而言,CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是**虚拟内存使用的是硬盘的空间**，为什么我们要使用速度最慢的硬盘来作为虚拟内存呢？因为电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用。

> 《交换空间和虚拟内存的区别》：https://blog.csdn.net/qsd007/article/details/1567955

# 42、抖动你知道是什么吗？它也叫颠簸现象

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)。

为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率。为了研究应该为每个进程分配多少个物理块，Denning 提出了“进程工作集”的概念。

# 43、从堆和栈上建立对象哪个快？（考察堆和栈的分配效率比较）

从两方面来考虑：

- 分配和释放，堆在分配和释放时都要调用函数（malloc,free)，比如分配时会到堆空间去寻找足够大小的空间（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。
- 访问时间，访问堆的一个具体单元，需要两次访问内存，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。

# 44、常见内存分配方式有哪些？

- 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。
- 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。
- 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

# 45、常见内存分配错误

（1）内存分配未成功，却使用了它。

编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行检查。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。

（2）内存分配虽然成功，但是尚未初始化就引用它。

犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。

（3）内存分配成功并且已经初始化，但操作越过了内存的边界。

例如在使用数组时经常发生下标“多1”或者“少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。

（4）忘记了释放内存，造成内存泄露。

含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然挂掉，系统出现提示：内存耗尽。动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。

（5）释放了内存却继续使用它。常见于以下有三种情况：

- 程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。
- 函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。
- 使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”。

> 《内存分配方式及常见错误》：https://www.cnblogs.com/skynet/archive/2010/12/03/1895045.html

# 46、内存交换中，被换出的进程保存在哪里？

保存在磁盘中，也就是外存中。具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式。对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。

# 47、在发生内存交换时，有些进程是被优先考虑的？你可以说一说吗？

可优先换出阻塞进程；可换出优先级低的进程；为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间… (注意: PCB 会常驻内存，不会被换出外存)

# 48、ASCII、Unicode和UTF-8编码的区别？

**ASCII**

ASCII 只有127个字符，表示英文字母的大小写、数字和一些符号，但由于其他语言用ASCII 编码表示字节不够，例如：常用中文需要两个字节，且不能和ASCII冲突，中国定制了GB2312编码格式，相同的，其他国家的语言也有属于自己的编码格式

**Unicode**

由于每个国家的语言都有属于自己的编码格式，在多语言编辑文本中会出现乱码，这样Unicode应运而生，Unicode就是将这些语言统一到一套编码格式中，通常两个字节表示一个字符，而ASCII是一个字节表示一个字符，这样如果你编译的文本是全英文的，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算

**UTF-8**

为了解决上述问题，又出现了把Unicode编码转化为“**可变长编码**”UTF-8编码，UTF-8编码将Unicode字符按数字大小编码为1-6个字节，英文字母被编码成一个字节，常用汉字被编码成三个字节，如果你编译的文本是纯英文的，那么用UTF-8就会非常节省空间，并且ASCII码也是UTF-8的一部分

**三者之间的联系**

搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：

(1) 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码

(2)用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件。如下图（截取他人图片）

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321104847.png)

浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321105017.png)

> 《字符编码中ASCII、Unicode和UTF-8的区别》：https://www.cnblogs.com/moumoon/p/10988234.html

# 49、原子操作的是如何实现的

**处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。**首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。

（1）使用总线锁保证原子性 

第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图下图所示。

```
CPU1    CPU2
 i=1     i=1
 i+1     i+1
 i=2     i=2
```

原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。

处理器使用总线锁来解决这个问题。**所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。**

（2）使用缓存锁保证原子性 

第二个机制是通过缓存锁定来保证原子性。在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但**总线锁定把CPU和内存之间的通信锁住了**，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。

频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能使用同时缓存i的缓存行。**

但是有两种情况下处理器不会使用缓存锁定。 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。

> 《原子操作的实现原理》：https://blog.csdn.net/zxx901221/article/details/83033998

# 50、内存交换你知道有哪些需要注意的关键点吗？

- 交换需要备份存储，通常是快速磁盘，它必须足够大，并且提供对这些内存映像的直接访问。
- 为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间，转移时间与所交换的空间内存成正比。
- 如果换出进程，比如确保该进程的内存空间成正比。
- 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
- 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
- 普通交换使用不多，但交换的策略的某些变种在许多系统中（如UNIX系统）仍然发挥作用。

# 51、系统并发和并行，分得清吗？

并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。

# 52、页面置换算法

（1）最佳置换法(OPT)

最佳置换算法(OPT，Optimal) ：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321110346.png)

最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的。

（2）先进先出置换算法(FIFO)

先进先出置换算法(FIFO) ：每次选择淘汰的页面是最早进入内存的页面 

实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头，页面队列的最大长度取决于系统为进程分配了多少个内存块。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321110751.png)

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321110840.png)

FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问，这些页在FIFO算法下被反复调入和调出。因此，算法性能差。并且有Belady现象。

Belady异常—当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。

只有FIFO算法会产生Belady异常，而LRU和OPT算法永远不会出现Belady异常。

（3）最近最久未使用置换算法(LRU)

最近最久未使用置换算法(LRU，least recently used) ：每次淘汰的页面是最近最久未使用的页面。

实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t（该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大）。当需要淘汰一个页面时，选择现有页面中 t 值最大的，即最近最久未使用的页面。

LRU性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类算法，理论上可以证明，堆栈类算法不可能出现Belady异常。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321111205.png)

在手动做题时，若需要淘汰页面，可以逆向检查此时在内存中的几个页面号。在逆向扫描过程中最后一个出现的页号就是要淘汰的页面。

（4）时钟置换算法(CLOCK)

最佳置换算法性OPT性能最好，但无法实现；先进先出置换算法实现简单，但算法性能差；最近最久未使用置换算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大。

所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体，因为算法要循环扫描缓冲区像时钟一样转动。时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法(NRU，Not Recently Used)

简单的CLOCK算法实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰-一个页面时，只需检查页的访问位。如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第~轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描(第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择–个淘汰页面最多会经过两轮扫描)

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321111749.png)

（5）改进型的时钟置换算法

简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。

因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。这就是改进型的时钟置换算法的思想。修改位=0，表示页面没有被修改过;修改位=1，表示页面被修改过。

为方便讨论，用(访问位，修改位)的形式表示各页面状态。如(1, 1)表示一个页面近期被访问过，且被修改过。

改进型的Clock算法需要综合考虑某一内存页面的访问位和修改位来判断是否置换该页面。在实际编写算法过程中，同样可以用一个等长的整型数组来标识每个内存块的修改状态。访问位A和修改位M可以组成以下四种类型的页面。

算法规则：将所有可能被置换的页面排成–个循环队列：

- 第一轮：从当前位置开始扫描到第一个(A =0, M = 0)的帧用于替换。表示该页面最近既未被访问，又未被修改，是最佳淘汰页 
- 第二轮：若第一轮扫描失败，则重新扫描，查找第一个(A =0, M = 1)的帧用于替换。本轮将所有扫描过的帧访问位设为0。表示该页面最近未被访问，但已被修改，并不是很好的淘汰页。 
- 第三轮：若第二轮扫描失败，则重新扫描，查找第一个(A =1, M = 0)的帧用于替换。本轮扫描不修改任何标志位。表示该页面最近已被访问，但未被修改，该页有可能再被访问。 
- 第四轮：若第三轮扫描失败，则重新扫描，查找第一个(A =1, M = 1)的帧用于替换。表示该页最近已被访问且被修改，该页可能再被访问。

由于第二轮已将所有帧的访问位设为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改进型CLOCK置换算法选择一个淘汰页面最多会进行四轮扫描。

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321112039.png)

**总结：**

|                         | 算法规则                                                     | 优缺点                                           |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------ |
| OPT                     | 优先淘汰最长时间内不会被访问的页面                           | 缺页率最小，性能最好，但无法实现                 |
| FIFO                    | 优先淘汰最先进入内存的页面                                   | 实现简单，但性能很差，可能出现Belady异常         |
| LRU                     | 优先淘汰最近最久没访问的页面                                 | 性能很好，但需要硬件支持，算法开销大             |
| CLOCK (NRU)             | 循环扫描各页面 第一轮淘汰访问位=0的，并将扫描过的页面访问位改为1。若第-轮没选中，则进行第二轮扫描。 | 实现简单，算法开销小，但未考虑页面是否被修改过。 |
| 改进型CLOCK (改进型NRU) | 用(访问位，修改位)的形式表述，进行淘汰                       | 算法开销较小，性能也不错                         |

# 53、共享是什么？

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。

互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

# 54、死锁相关问题

死锁是指两个（多个）线程相互等待对方数据的过程，死锁的产生会导致程序卡死，不解锁程序将永远无法进行下去。

**（1）死锁产生原因**

举个例子：两个线程A和B，两个数据1和2。线程A在执行过程中，首先对资源1加锁，然后再去给资源2加锁，但是由于线程的切换，导致线程A没能给资源2加锁。线程切换到B后，线程B先对资源2加锁，然后再去给资源1加锁，由于资源1已经被线程A加锁，因此线程B无法加锁成功，当线程切换为A时，A也无法成功对资源2加锁，由此就造成了线程AB双方相互对一个已加锁资源的等待，死锁产生。

理论上认为死锁产生有以下四个必要条件，缺一不可：

- **互斥条件**：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。
- **不可剥夺条件**：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。
- **请求和保持条件**：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。
- **循环等待条件**：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。

（2）死锁演示

通过代码的形式进行演示，需要两个线程和两个互斥量。

```cpp
#include <iostream>
#include <vector>
#include <list>
#include <thread>
#include <mutex>  //引入互斥量头文件
using namespace std;

class A {
public:
	//插入消息，模拟消息不断产生
	void insertMsg() {
		for (int i = 0; i < 100; i++) {
			cout << "插入一条消息:" << i << endl;
			my_mutex1.lock(); //语句1
			my_mutex2.lock(); //语句2
			Msg.push_back(i);
			my_mutex2.unlock();
			my_mutex1.unlock();
		}
	}
	//读取消息
	void readMsg() {
		int MsgCom;
		for (int i = 0; i < 100; i++) {
			MsgCom = MsgLULProc(i);
			if (MsgLULProc(MsgCom)) {
				//读出消息了
				cout << "消息已读出" << MsgCom << endl;
			}
			else {
				//消息暂时为空
				cout << "消息为空" << endl;
			}
		}
	}
	//加解锁代码
	bool MsgLULProc(int &command) {
		int curMsg;
		my_mutex2.lock();   //语句3
		my_mutex1.lock();   //语句4
		if (!Msg.empty()) {
			//读取消息，读完删除
			command = Msg.front();
			Msg.pop_front();
			
			my_mutex1.unlock();
			my_mutex2.unlock();
			return true;
		}
		my_mutex1.unlock();
		my_mutex2.unlock();
		return false;
	}
private:
	std::list<int> Msg;  //消息变量
	std::mutex my_mutex1; //互斥量对象1
	std::mutex my_mutex2; //互斥量对象2
};

int main() {
	A a;
	//创建一个插入消息线程
	std::thread insertTd(&A::insertMsg, &a); //这里要传入引用保证是同一个对象
	//创建一个读取消息线程
	std::thread readTd(&A::readMsg, &a); //这里要传入引用保证是同一个对象
	insertTd.join();
	readTd.join();
	return 0;
}
```

语句1和语句2表示线程A先锁资源1，再锁资源2，语句3和语句4表示线程B先锁资源2再锁资源1，具备死锁产生的条件。

（3）死锁的解决方案

保证上锁的顺序一致。

（4）处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

**(5)鸵鸟策略**

把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

**(6)死锁检测与死锁恢复**

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1、每种类型一个资源的死锁检测

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321115320.png)

上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

2、每种类型多个资源的死锁检测

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321115423.png)

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

- 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
- 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
- 如果没有这样一个进程，算法终止。

**死锁恢复**

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

**(7)死锁预防**

在程序运行之前预防发生死锁。

- 破坏互斥条件

  例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

- 破坏不剥夺条件

  允许抢占资源

- 破坏请求和保持条件

  一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

- 破坏循环请求等待

  给资源统一编号，进程只能按编号顺序来请求资源。

**(8)死锁避免**

在程序运行时避免发生死锁。

1. **安全状态**

   ![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321115908.png)

   图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态是安全的。

   定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

   安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。

2. 单个资源的银行家算法

   一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

   ![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321120211.png)

   上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

3. 多个资源的银行家算法

   ![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321120300.png)

   上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

4. 检查一个状态是否安全的算法

   - 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
   - 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
   - 重复以上两步，直到所有进程都标记为终止，则状态是安全的。

   如果一个状态不是安全的，需要拒绝进入这个状态。

# 55、为什么分段式存储管理有外部碎片而无内部碎片？为什么固定分区分配有内部碎片而不会有外部碎片？

分段式分配是按需分配，而固定式分配是固定分配的方式。

# 56、内部碎片与外部碎片

- 内碎片：分配给某些进程的内存区域中有些部分没用上，常见于固定分配方式。

  内存总量相同（100M）

  - 固定分配，将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M，剩下的5M就是内部碎片
  - 分段式分配，按需分配，一个程序需要45M，就给分片45MB，剩下的55M供其它程序使用，不存在内部碎片

- 外碎片：内存中某些空闲区因为比较小，而难以利用上，一般出现在内存动态分配方式中

  分段式分配：内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序使用，只能从头开始分片，这样，就会存在10M+5M的外部碎片

# 57、如何消除外部碎片

- 紧缩法，紧缩的目的就是移动内存内容，以便所有空闲空间合并成一整块，但是紧缩并不是所有的程序都是可以的，因为如果重定位是静态的，也就是说在汇编时或装入内存的时候进行的，那么就不能紧缩，紧缩只是在重定位是动态并且在运行时可以采用，如果地址被动态重定位，就可以去移动程序和数据，然后去根据新基地址的值来改变基地址寄存器，如果我们采用了紧缩，我们还要去估计其的开销，最简单的合并算法就是去将所有进程移动内存的一端，而将所有的孔移动到内存的另一端，这样以生成一个大的空闲快，不过这种方案的开销大
- 还有一种就是可以是允许物理地址空间为非连续，这样的话，只需要有物理地址就可以为进程去分配空间了

# 58、什么是操作系统？

- 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的软件程序，是计算机系统的内核与基⽯；
- 操作系统为⽤户提供⼀个与系统交互的操作界⾯ ；
- 操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应⽤程序，⽽内核就是能操作硬件的程序）。

# 59、用户态和内核态

在计算机系统中，分两种程序：系统程序和应用程序，为了保证系统程序不被应用程序有意或无意地破坏，为计算机设置了两种状态——用户态、内核态。

**用户态：** 只能受限的访问内存，运行所有的应用程序

**内核态：** 运行操作系统程序，cpu可以访问内存的所有数据，包括外围设备

# 60、用户态切换到内核态的方式

- **系统调用**

  这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。

- **异常**

  当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

- **外围设备的中断**

  当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

# 61、操作系统内存管理方式，分页分段以及段页式的优缺点

分页式管理、分段式管理、段页式管理

（1）分页管理

在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）

内部碎片：通常将内存以固定大小的块为单位来分配，进程所分配的内存可能要比所要的要大，这两个数字之差就称为内部碎片，这部分内存在分区当中，不过不能使用。

（2）分段管理

在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

外部碎片：随着进程装入和移出内存，空闲的内存空间被分为小片段，当所有的空闲的这些小片段的内存之和可以满足请求，但是并不连续的时候，这个时候就会出现外部碎片的问题，这个问题可能会很严重，这个就是外部碎片。

（3）段页式管理

段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若干段，每个段⼜分成若干页，也就是说段⻚式管理机制中段与段之间以及段的内部都是离散的。

（4）分段分页的相同点和区别

共同点 ：

   - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

区别：

   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

# 62、CPU 寻址

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

![](https://cdn.jsdelivr.net/gh/Simpleforever/imgbed/pic2/20210321144135.png)

逻辑(虚拟)地址：我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。

物理地址: 指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

# 63、为什么要有虚拟地址空间呢？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，**造成操作系统崩溃。**
2. 程序地址一般是从1开始编号，直接访问物理地址会造成冲突，**使得同时运行多个程序特别困难。**比如你想同时运行一个微信和一个 QQ ：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

# 64、快表

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

# 65、多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章

- 多级页表如何节约内存：[https://www.polarxiong.com/archives/多级页表如何节约内存.html](https://www.polarxiong.com/archives/多级页表如何节约内存.html)

# 66、[什么是虚拟内存(Virtual Memory)?](https://zh.wikipedia.org/wiki/虚拟内存)

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。

**虚拟内存的技术实现**：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟内存的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分页面即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

请求分页与分页存储管理，两者有何不同呢？

它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

# 67、进程分配的资源包括哪些？

- 标识相关：pid，ppid等等
- 文件相关：进程需要记录打开的文件信息，于是需要文件描述符表
- 内存相关：内存指针，指向进程的虚拟地址空间（用户空间）信息
- 优先级相关：进程相对于其他进程的调度优先级
- 上下文信息相关：CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
- 状态相关：进程当前的状态，说明该进程处于什么状态
- 信号相关：进程的信号处理函数，以及记录当前进程是否还有待处理的信号
- I/O相关：记录进程与各种I/O设备之间的交互

# 68、线程共享的信息包含哪些

- 文件描述符表
- 每种信号的处理方式（SIG_IGN、SIG_DFL或者自定义的信号处理函数） 
- 当前工作目录 
- 用户id和组id
- 地址空间

# 69、线程独有的信息有哪些

- 线程id 
- 上下文信息，包括各种寄存器的值、程序计数器和栈指针
- 栈空间（临时变量存储在栈空间中）
- errno变量
- 信号屏蔽字 
- 调度优先级

# 70、进程切换复杂体现在什么地方？

最主要的一个区别在于进程切换涉及虚拟地址空间的切换而线程不会。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

现在我们已经知道了进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是TLB（translation Lookaside Buffer，我们不需要关心这个名字只需要知道TLB本质上就是一个cache，是用来加速页表查找的）。由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。

# 71、进程何时处理信号？

- 由内核态到用户态时会进行 do_signal()函数判断是否有信号

  